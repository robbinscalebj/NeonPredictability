---
title: "theory"
author: "Caleb Robbins"
date: "7/22/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(here)
library(arrow)
library(neon4cast)
library(yardstick)
source(here("download_target.R"))
```


Ripping this code from Freya Olsson's tutorial: https://github.com/OlssonF/NEON-forecast-challenge-workshop/blob/main/Analyse_scores/Get_scores_tutorial.Rmd

# Vision for new forecasts
- Rerun random forest
-- Fill in gaps
-- Make sure we know where forecasts start and end (e.g., run forecasts from January to January)

- New model structure
-- Incorporate initial conditions
-- Incorporate time series window training

- New model sensitivity analysis
-- How sensitive are results to:
--- Data availability
--- Models updating
--- Training conditions
--- Site as predictor (one model all sites)

# Vision for analysis
- Questions: 
-- How does predictability vary across ecological variables, time, and spatial scales?
--- Are different ecological variables more predictable than others? 

- Response variable
-- Normed RMSE (preferably) or normed R2
-- Aggregate for error metric - monthly scale (n = 4 for beetles and ticks, n = ~30 for others)
-- Normalizing to null model could be problematic - for example, the persistence, mean, or climatology models offer information that could make it look like our model predictability is lower, just because the null model predicted well. Maybe that's the point.


# Download forecasts

```{r}
s3_aquatic <- arrow::s3_bucket(bucket = "neon4cast-scores/parquet/aquatics", endpoint_override= "data.ecoforecast.org")
s3_pheno <- arrow::s3_bucket(bucket = "neon4cast-scores/parquet/phenology", endpoint_override= "data.ecoforecast.org")
s3_terr <- arrow::s3_bucket(bucket = "neon4cast-scores/parquet/terrestrial_daily", endpoint_override= "data.ecoforecast.org")
s3_beetle <- arrow::s3_bucket(bucket = "neon4cast-scores/parquet/beetles", endpoint_override= "data.ecoforecast.org")

start_ref_date <- as_date('2023-04-13') # what period do you want the scores for?
end_ref_date <- as_date('2023-09-14')
get_refdates <- as.character(seq(start_ref_date, end_ref_date, by = 'day'))

get_sites <- readr::read_csv("https://raw.githubusercontent.com/eco4cast/neon4cast-targets/main/NEON_Field_Site_Metadata_20220412.csv", show_col_types = F) |> 
  #dplyr::filter(field_site_subtype == 'Wadeable Stream') |> # Subset to the stream sites
  select(field_site_id) |> #slice_head(n = 5)|>
  pull() # get in a vector

get_variables <- c('temperature', 'oxygen', "gcc90", "nee", "abundance")

aq_scores <- open_dataset(s3_aquatic) |>
  filter(reference_datetime %in% get_refdates,
         model_id == "tg_randfor",
         site_id %in% get_sites,
         variable %in% get_variables) |> 
  collect() |> 
  mutate(horizon = as.numeric(as_date(datetime) - as_date(reference_datetime)))

beetle_scores <- open_dataset(s3_beetle) |>
  filter(reference_datetime %in% get_refdates,
         model_id == "tg_randfor",
         site_id %in% get_sites,
         variable %in% get_variables) |> 
  collect() |> 
  mutate(horizon = as.numeric(as_date(datetime) - as_date(reference_datetime)))

terr_scores <- open_dataset(s3_terr) |>
  filter(reference_datetime %in% get_refdates,
         model_id == "tg_randfor",
         site_id %in% get_sites,
         variable %in% get_variables) |> 
  collect() |> 
  mutate(horizon = as.numeric(as_date(datetime) - as_date(reference_datetime)))

pheno_scores <- open_dataset(s3_pheno) |>
  filter(reference_datetime %in% get_refdates,
        # model_id == "tg_randfor",
         site_id %in% get_sites,
         variable %in% get_variables) |> 
  collect() |> 
  mutate(horizon = as.numeric(as_date(datetime) - as_date(reference_datetime)))

scores_df <- bind_rows(aq_scores, beetle_scores,terr_scores) # fix pheno

```
#download historical means
```{r}

targets_vec <- c("aquatics", "terrestrial_daily", "beetles")

aq_hist <- map(targets_vec, ~download_target(.))|>
  list_rbind()

hist_mean_obs <- aq_hist|>
  filter(datetime < as_date ("2023-01-01"))|>
  group_by(variable, site_id)|>
  summarize(mean_historical_observation = mean(observation, na.rm = TRUE))


```

```{r calculate error metric}

test <- scores_df|>filter(site_id == "ARIK")|>
  #filter(variable == "temperature", site_id == "ARIK", reference_datetime %in% c("2023-04-14", "2023-04-15","2023-05-14", "2023-05-15"))|>
  left_join(hist_mean_obs)

df2 <- test|>group_by(variable)|>
  mutate(forecast_month = month(reference_datetime))|>
  filter(horizon >= 0)|>
  relocate(forecast_month)|>
  mutate(modobs_diff = observation-mean)|>
  group_by(variable, reference_datetime, site_id)|>
  mutate(initial_obs = first(observation))|>
  group_by(variable, horizon, forecast_month, site_id)|>
  summarize(mean_hist_obs = mean(mean_historical_observation), #simplifies summarisation - same value being averaged so nothing changed
            N_non_na_obs = sum(!is.na(modobs_diff)),
            randfor_rmse = sqrt(sum((modobs_diff)^2, na.rm = TRUE))/n(),
            randfor_rmse2 = sqrt(sum((modobs_diff)^2, na.rm = TRUE))/N_non_na_obs, #test with non-NA
            randfor_rmse_normed = randfor_rmse/mean_hist_obs,
            persistence_rmse = sqrt(sum((initial_obs)^2, na.rm = TRUE))/n(), #don't know if n(0 correctly counting NAs)
            persistence_rmse_normed = persistence_rmse/mean_hist_obs,
            forecast_skill = 1 - (randfor_rmse_normed/persistence_rmse_normed)
            )

# there appear to be no nee observations at SOAP for at least a time period


blah <- scores_df|>group_by(variable)|>slice_head(n = 10000)|>filter(variable == "nee" & site_id == "SOAP")
```

```{r}

ggplot(df2|>filter(variable == "temperature"), aes(x = horizon, y = observation))+
  geom_point()
```


ggplot(data = blah, aes(x = horizon, y = mean-observation, color = variable))+
  geom_point()+
  facet_wrap(.~site_id)

# calculate R 2 for each forecast horizon and site

score_sums <- scores_df|>filter(horizon >=0)|>mutate(month = month(reference_datetime))|>group_by(variable,horizon, site_id, month)|>rsq(truth = observation, estimate = median)|>rename(r_squared = ".estimate")

ggplot(data = score_sums|>filter(variable == "oxygen"), aes(x = horizon, y = r_squared))+
  geom_point()+
  facet_wrap(.~month)+
  geom_smooth(method = "gam")

#suppose what we want to do is aggregate scores for each forecast horizon

```

View time series observations

```{r}

modobs <- read_csv(here("Generate_forecasts/tg_randfor/model_training_summaries.csv"))

ggplot(data = modobs, aes(x = target_variable, y = n_obs))+
  geom_point()+
  facet_wrap(.~theme, scales = "free")+
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5))

```



```{r}
unique(scores_df$variable)
m1 <- gam(data = scores_df, 
          s(horizon, by = variable) +
          s(horizon, by = c(variable, season))+
          s(variable, bs = "re")+
          s(site_id, bs = "re")+
          s(site_id, horizon, bs = "re"))


```


View target observations
```{r}

aquatic_df <- download_target("aquatics")
beetle_df<- download_target("beetles")

beetle_t<- beetle_df|>
  pivot_wider(names_from = "variable", values_from = "observation")|>
  filter(abundance > 0)

ggplot(beetle_df|>mutate()|>filter(variable == "richness"), 
       aes(x = datetime, y = observation, color = site_id))+
  geom_line()

```