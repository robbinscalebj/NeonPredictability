---
title: "theory"
author: "Caleb Robbins"
date: "7/22/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(here)
library(arrow)
library(neon4cast)
library(yardstick)
library(mgcv)
library(tidymv)
source(here("download_target.R"))
```


Ripping this code from Freya Olsson's tutorial: https://github.com/OlssonF/NEON-forecast-challenge-workshop/blob/main/Analyse_scores/Get_scores_tutorial.Rmd

# Vision for new forecasts
- Rerun random forest
-- Fill in gaps
-- Make sure we know where forecasts start and end (e.g., run forecasts from January to January)

- New model structure
-- Incorporate initial conditions
-- Incorporate time series window training

- New model sensitivity analysis
-- How sensitive are results to:
--- Data availability
--- Models updating
--- Training conditions
--- Site as predictor (one model all sites)

# Vision for analysis
- Questions: 
-- How does predictability vary across ecological variables, time, and spatial scales?
--- Are different ecological variables more predictable than others? 

- Response variable
-- Normed RMSE (preferably) or normed R2
-- Aggregate for error metric - monthly scale (n = 4 for beetles and ticks, n = ~30 for others)
-- Normalizing to null model could be problematic - for example, the persistence, mean, or climatology models offer information that could make it look like our model predictability is lower, just because the null model predicted well. Maybe that's the point.


# Download forecasts

```{r}
s3_aquatic <- arrow::s3_bucket(bucket = "neon4cast-scores/parquet/aquatics", endpoint_override= "data.ecoforecast.org")
s3_pheno <- arrow::s3_bucket(bucket = "neon4cast-scores/parquet/phenology", endpoint_override= "data.ecoforecast.org")
s3_terr <- arrow::s3_bucket(bucket = "neon4cast-scores/parquet/terrestrial_daily", endpoint_override= "data.ecoforecast.org")
s3_beetle <- arrow::s3_bucket(bucket = "neon4cast-scores/parquet/beetles", endpoint_override= "data.ecoforecast.org")

start_ref_date <- as_date('2023-04-13') # what period do you want the scores for?
end_ref_date <- as_date('2023-09-14')
get_refdates <- as.character(seq(start_ref_date, end_ref_date, by = 'day'))

get_sites <- readr::read_csv("https://raw.githubusercontent.com/eco4cast/neon4cast-targets/main/NEON_Field_Site_Metadata_20220412.csv", show_col_types = F) |> 
  #dplyr::filter(field_site_subtype == 'Wadeable Stream') |> # Subset to the stream sites
  select(field_site_id) |> #slice_head(n = 5)|>
  pull() # get in a vector

get_variables <- c('temperature', 'oxygen', "gcc_90", "nee", "abundance")

aq_scores <- open_dataset(s3_aquatic) |>
  filter(reference_datetime %in% get_refdates,
         model_id == "tg_randfor",
         site_id %in% get_sites,
         variable %in% get_variables) |> 
  collect() |> 
  mutate(horizon = as.numeric(as_date(datetime) - as_date(reference_datetime)))

beetle_scores <- open_dataset(s3_beetle) |>
  filter(reference_datetime %in% get_refdates,
         model_id == "tg_randfor",
         site_id %in% get_sites,
         variable %in% get_variables) |> 
  collect() |> 
  mutate(horizon = as.numeric(as_date(datetime) - as_date(reference_datetime)))

terr_scores <- open_dataset(s3_terr) |>
  filter(reference_datetime %in% get_refdates,
         model_id == "tg_randfor",
         site_id %in% get_sites,
         variable %in% get_variables) |> 
  collect() |> 
  mutate(horizon = as.numeric(as_date(datetime) - as_date(reference_datetime)))

pheno_scores <- open_dataset(s3_pheno) |>
  filter(reference_datetime %in% get_refdates,
        # model_id == "tg_randfor",
         site_id %in% get_sites,
         variable %in% get_variables) |> 
  collect() |> 
  mutate(horizon = as.numeric(as_date(datetime) - as_date(reference_datetime)))

scores_df <- bind_rows(aq_scores, beetle_scores,terr_scores) # fix pheno

```

#Download locally re-run forecasts

fc_list <- list.files("D:/EFI_Forecast_Reruns/", full.names = TRUE)
tic()
plan(multisession, workers = 4)
forecasts <- future_map(fc_list, ~read_csv(.)|>
                   group_by(variable,datetime,reference_datetime, site_id)|>
                   summarize(mean = mean(prediction), sd = sd(prediction)))|>
  list_rbind()|>
  mutate(horizon = interval(reference_datetime, datetime)|>as.numeric("days"))
toc()


write_parquet(forecasts, sink = here("Summarized_Forecasts/randfor.parquet"))
```{r}
forecasts <- read_parquet(here("Summarized_Forecasts/randfor.parquet"))
```

#download historical means
```{r}

targets_vec <- c("aquatics", "terrestrial_daily", "beetles", "ticks", "phenology")

blah <- download_target("beetles")
beet_test <- read_csv("https://data.ecoforecast.org/neon4cast-targets/beetles/beetles-targets.csv.gz", guess_max = 1e6)
tar_hist <- map(targets_vec, ~download_target(.))|>
  list_rbind()

ggplot(data = tar_hist|>filter(variable == "oxygen"), aes(x = datetime, y = observation))+
  geom_point()+
  facet_grid(.~variable)

ggplot(data = beet_test|>filter(variable == "richness"), aes(x = datetime, y = observation))+
  geom_point()+
  facet_grid(.~variable)

ggplot(data = beet_test|>filter(variable == "richness")|>mutate(year = year(datetime)), aes(x = datetime, y = observation))+
  geom_histogram()+
  facet_grid(.~year)

ggplot(data = beet_test|>
         mutate(year = as_factor(year(datetime)))|>
         filter(variable == "richness", datetime > as_date("2019-01-01")), 
       aes(x = observation, color = year))+
  geom_density()+
  facet_wrap(.~year)
  
hist_mean_obs <- tar_hist|>
  filter(datetime < as_date ("2023-01-01"))|>
  group_by(variable, site_id)|>
  summarize(mean_historical_observation = mean(observation, na.rm = TRUE),
            iq_range = quantile(observation,0.75, na.rm = TRUE)-quantile(observation, 0.25, na.rm = TRUE))


```

```{r calculate error metric}
forecasts2 <- forecasts|>
  left_join(tar_hist)

test <- forecasts2|>#filter(site_id == "ARIK")|>
  #filter(variable == "temperature", site_id == "ARIK", reference_datetime %in% c("2023-04-14", "2023-04-15","2023-05-14", "2023-05-15"))|>
  left_join(hist_mean_obs)
unique(test$site_id)

df2 <- test|>group_by(variable)|>
  mutate(forecast_month = month(reference_datetime))|>
  filter(horizon >= 0)|>
  relocate(forecast_month)|>
  mutate(modobs_diff = observation-mean,
         modmean_diff = observation - mean_historical_observation)|>
  group_by(variable, reference_datetime, site_id)|>
  mutate(initial_obs = first(observation))|>
  group_by(variable, horizon, site_id)|>
  summarize(mean_hist_obs = mean(mean_historical_observation), #simplifies summarisation - same value being averaged so nothing changed
            N_non_na_obs = sum(!is.na(modobs_diff)),
            randfor_rmse = sqrt(sum((modobs_diff)^2, na.rm = TRUE)/n()),
            randfor_rmse2 = sqrt(sum((modobs_diff)^2, na.rm = TRUE)/N_non_na_obs), #test with non-NA
            randfor_rmse_normed = randfor_rmse/mean_hist_obs,
            randfor_rmse_normed2 = randfor_rmse2/mean_hist_obs,
            randfor_rmse_normed3 = randfor_rmse2/iq_range,
            persistence_rmse = sqrt(sum((initial_obs)^2, na.rm = TRUE))/n(), #don't know if n(0 correctly counting NAs)
            persistence_rmse_normed = persistence_rmse/mean_hist_obs,
            forecast_skill = 1 - (randfor_rmse_normed/persistence_rmse_normed),
            R2_num = sum((modobs_diff)^2, na.rm = TRUE),
            R2_denom = sum((modmean_diff)^2, na.rm = TRUE),
            R2 = 1-(R2_num/R2_denom), # this is also NSE 
            NSE_normed = 1/(2-R2)
            )|>
  filter(!(variable %in% c("abundance", "amblyomma_americanum", "richness")))

# there appear to be no nee observations at SOAP for at least a time period


blah <- scores_df|>group_by(variable)|>slice_head(n = 10000)|>filter(variable == "nee" & site_id == "SOAP")
blah <- df2|>filter(R2<0)
```

```{r}

ggplot(df2|>group_by(horizon, variable)|>summarize(mean = mean(randfor_rmse_normed3, na.rm = TRUE),sd = sd(randfor_rmse_normed3, na.rm = TRUE)), 
       aes(x = horizon, y = mean, color = variable))+
  geom_errorbar(aes(x = horizon, ymin = mean-sd, ymax = mean+sd))+
  geom_smooth(method = "gam")+
  facet_grid(.~variable)

ggplot(df2|>group_by(horizon, variable)|>summarize(mean = mean(NSE_normed, na.rm = TRUE),sd = sd(NSE_normed, na.rm = TRUE)), 
       aes(x = horizon, y = mean, color = variable))+
  geom_errorbar(aes(x = horizon, ymin = mean-sd, ymax = mean+sd))+
  geom_smooth(method = "gam")+
  facet_grid(.~variable)

ggplot(df2|>group_by(variable, horizon, site_id)|>summarize(rmse_normed = mean(randfor_rmse_normed3,na.rm = TRUE)), 
       aes(x = horizon, y = rmse_normed, color = variable))+
  geom_point()+
  facet_grid(.~variable)+
  ylab("Interquartile-range Normalized RMSE")

ggplot(df2|>group_by(variable, horizon, site_id)|>summarize(NSE_normed = mean(NSE_normed,na.rm = TRUE)), 
       aes(x = horizon, y = NSE_normed, color = variable))+
  geom_point()+
  facet_grid(.~variable)+
  ylab("Normalized NSE")

#which site is being predicted really poorly?
blah <- df2|>filter(variable == "nee" &randfor_rmse_normed3>3.5) #CPER, but not because of a small IQR

```


ggplot(data = blah, aes(x = horizon, y = mean-observation, color = variable))+
  geom_point()+
  facet_wrap(.~site_id)

# calculate R 2 for each forecast horizon and site

score_sums <- scores_df|>filter(horizon >=0)|>mutate(month = month(reference_datetime))|>group_by(variable,horizon, site_id, month)|>rsq(truth = observation, estimate = median)|>rename(r_squared = ".estimate")

ggplot(data = score_sums|>filter(variable == "oxygen"), aes(x = horizon, y = r_squared))+
  geom_point()+
  facet_wrap(.~month)+
  geom_smooth(method = "gam")

#suppose what we want to do is aggregate scores for each forecast horizon



View time series observations

```{r}

modobs <- read_csv(here("Generate_forecasts/tg_randfor/model_training_summaries.csv"))

ggplot(data = modobs, aes(x = target_variable, y = n_obs))+
  geom_point()+
  facet_wrap(.~theme, scales = "free")+
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5))

```



```{r}
df_gam <- df2|>filter(!(variable %in% c("abundance", "richness", "amblyomma_americanum")))|>
  filter(is.numeric(R2), R2 >0 & R2 <1)|>
  mutate(variable = as_factor(variable),
         forecast_month = as_factor(forecast_month),
         site_id = as_factor(site_id))|>
  mutate(var_month = interaction(forecast_month, variable))
unique(df_gam$var_month)

cl <- parallel::makeCluster(4)
#this runs pretty fast
m0 <- bam(data = df_gam, R2 ~ horizon + variable + var_month +
          s(horizon, by = variable)+
          s(horizon, by = var_month)+
          s(site_id, bs = "re")+
          s(site_id, horizon, bs = "re"),
          clsuter = cl)

write_rds(m0, here("test_gam.rds"))



```

```{r}
summary(m0)

m0.pred <- predict_gam(m0, length_out = 100, exclude_terms = c("s(site_id)", "s(site_id,horizon)"),
                       values = list(site_id = NULL, horizon = seq(1,30, by = 1)))|>
  separate_wider_delim(cols = var_month, names = c("forecast_month", "blah"), delim = ".")|>
  mutate(forecast_month = as.numeric(forecast_month))|>
  mutate(forecast_month_abb = case_when(forecast_month == "1" ~ "Jan",
                                        forecast_month == "2" ~ "Feb",
                                        forecast_month == "3" ~ "Mar",
                                        forecast_month == "4" ~ "Apr",
                                        forecast_month == "5" ~ "May",
                                        forecast_month == "6" ~ "June",
                                        forecast_month == "7" ~ "July",
                                        forecast_month == "8" ~ "Aug",
                                        forecast_month == "9" ~ "Sep",
                                        forecast_month == "10" ~ "Oct"),#jeez, I know there's a shorter way to recode this
         forecast_month_abb = fct_reorder(forecast_month_abb, forecast_month),
         variable = fct_recode(variable,`Chlorophyll-a`= "chla", Greenness = "gcc_90", Redness = "rcc_90", Evapotranspiration = "le", `Net Ecosystem Exchange` = "nee", `Dissolved O2` = "oxygen",  `Water Temp` = "temperature"))|>
  rename(R2 = "fit")

ggplot(data = m0.pred, aes(x = horizon, y = R2, color = variable))+
  geom_smooth(se=FALSE)+
  facet_wrap(.~forecast_month_abb)+
  xlab("Forecast Horizon (days)")+
  ylab(bquote(bold(R^2)))+
  theme_bw()+
  theme(legend.position  = c(0.75,0.15), legend.title = element_blank(),
        axis.title.y = element_text(size = 18),axis.title.x = element_text(size = 18, face = "bold"),
        axis.text.x = element_text(face = "bold"), axis.text.y = element_text(face = "bold"),
        strip.text = element_text(face = "bold", size = 12), legend.text = element_text(size = 10, face = "bold"))+
  guides(color=guide_legend(nrow=4))



```


View target observations
```{r}

aquatic_df <- download_target("aquatics")
beetle_df<- download_target("beetles")

beetle_t<- beetle_df|>
  pivot_wider(names_from = "variable", values_from = "observation")|>
  filter(abundance > 0)

ggplot(beetle_df|>mutate()|>filter(variable == "richness"), 
       aes(x = datetime, y = observation, color = site_id))+
  geom_line()

```


```{r}
library(mgcv)
nee_df <- df2|>ungroup()|>filter(variable == "nee", is.numeric(R2), R2 >=0)|>
  mutate(forecast_month = as_factor(forecast_month),
         site_id = as_factor(site_id))|>
  mutate(month_site = interaction(forecast_month, site_id))


m1 <- gam(R2 ~ s(horizon)+
            s(horizon, by = month_site), 
          data = nee_df)


```